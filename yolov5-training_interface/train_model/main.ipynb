{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f433c3da",
   "metadata": {},
   "source": [
    "# Exporting weights into different format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python export.py --weights runs/train/exp3/weights/best.pt --include pb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7126ef5",
   "metadata": {},
   "source": [
    "# Detection - you can pass: video, image or a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b350856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs/train/exp3/weights/best.pt --img 640 --conf 0.3 --source C:/Users/Mateusz/OneDrive/Desktop/test_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c58709",
   "metadata": {},
   "source": [
    "# Detection - from a webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs/train/exp3/weights/best.pt --img 640 --conf 0.3 --source 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca56b8c",
   "metadata": {},
   "source": [
    "# Move labelled images from one folder to folder compliant with YOLO folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images_with_labels(from_folder_path = '../test_imgs',\n",
    "                            to_folder_path = '../train_data/images/train',\n",
    "                            labels_path = '../train_data/labels/train'):\n",
    "    import os,shutil\n",
    "    from_folder = os.listdir(from_folder_path)\n",
    "    labels = os.listdir(labels_path)\n",
    "\n",
    "    for el in labels:\n",
    "        if f'{el[:-4]}.jpg' in from_folder:\n",
    "            shutil.move(f'{from_folder_path}/{el[:-4]}.jpg',f'{to_folder_path}/{el[:-4]}.jpg')\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12fa94",
   "metadata": {},
   "source": [
    "# Set Up + train model(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe68e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def setup_model(clone_repo_and_install_req = False, \n",
    "                clear_pycatche = True,\n",
    "                train = True):\n",
    "\n",
    "    def clear_pychatche(list_of_directories=['.','./models','./utils']):\n",
    "        import os,shutil\n",
    "\n",
    "        for path in list_of_directories:\n",
    "            for el in os.listdir(path):\n",
    "                if el =='__pycache__':\n",
    "                    shutil.rmtree(path+'/'+el)\n",
    "\n",
    "    if clone_repo_and_install_req:\n",
    "        !git clone https://github.com/ultralytics/yolov5\n",
    "\n",
    "    %cd yolov5\n",
    "    %pip install -qr requirements.txt psutil wandb\n",
    "\n",
    "    import utils\n",
    "    display = utils.notebook_init()\n",
    "\n",
    "\n",
    "######### this part needs to be changed before custom training #########\n",
    "    if train:\n",
    "        !python train.py --img 640 --batch 1 --epochs 1 --data custom_classes.yaml  --weights yolov5s.pt --cache   \n",
    "########################################################################\n",
    "\n",
    "    if clear_pycatche:\n",
    "        clear_pychatche()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector:\n",
    "\n",
    "    def __init__(self, \n",
    "                 weights_path = 'yolov5/runs/train/exp3/weights/best.pt' ):\n",
    "                 \n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path = weights_path)\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model.to(device)\n",
    "\n",
    "    def calculate_boxes(self,results, \n",
    "                    frame, \n",
    "                    detection_treshold = 0.6, \n",
    "                    draw_bbox = True, \n",
    "                    draw_center = True, \n",
    "                    return_cords = True):\n",
    "\n",
    "        labels, bbox, scores = results     \n",
    "        x_shape, y_shape = frame.shape[1], frame.shape[0]   \n",
    "        bbox = list(bbox)\n",
    "        \n",
    "        if len(scores) > 0:\n",
    "                scores = list(map(float, scores.reshape(1, -1)[0]))\n",
    "                \n",
    "                indices = cv2.dnn.NMSBoxes(bboxes=bbox, scores=scores, score_threshold=detection_treshold, nms_threshold=0.8)\n",
    "\n",
    "                for i in indices:\n",
    "                        box = bbox[i]\n",
    "                        x1, y1, w, h = int(box[0]*x_shape), int(box[1]*y_shape), int(box[2]*x_shape/2), int(box[3]*y_shape/2)\n",
    "\n",
    "                        center = x1,y1\n",
    "                        radius_w, radius_h = w,h \n",
    "\n",
    "                        if draw_center:\n",
    "                                cv2.circle(frame, center=(x1,y1),radius=0, color=(0, 0, 255), thickness=5)\n",
    "                                                       \n",
    "                        if draw_bbox:\n",
    "                                bgr = (0, 255, 0)\n",
    "                                cv2.rectangle(frame, (x1-w, y1-h), (x1+w, y1+h), bgr, 2)\n",
    "\n",
    "                        if return_cords:\n",
    "                                return frame, center, radius_w, radius_h\n",
    "                              \n",
    "        return frame, 0, 0, 0,\n",
    "    \n",
    "    def find_bboxes(self,frame):\n",
    "                \n",
    "                \n",
    "        frame = [frame]\n",
    "        results = self.model(frame)\n",
    "                \n",
    "        labels, bbox, scores = results.xywhn[0][:, -1], results.xywhn[0][:, :-2], results.xywhn[0][:, -2:-1]\n",
    "\n",
    "        #format required by cv2.dnn.NMS      \n",
    "        return np.array(labels.cpu()), np.array(bbox.cpu()), np.array(scores.cpu())\n",
    "\n",
    "    def run_detection(self):\n",
    "\n",
    "        while True:\n",
    "\n",
    "                success, frame = self.cap.read()\n",
    "                \n",
    "                if not success:\n",
    "                        break\n",
    "                        \n",
    "                results = self.find_bboxes(frame)\n",
    "                frame, center, radius_w, radius_h = self.calculate_boxes(results, frame)\n",
    "                \n",
    "                if radius_w>0:\n",
    "                        yield center, radius_w, radius_h\n",
    "\n",
    "                # cv2.imshow(frame,'vid')\n",
    "                k = cv2.waitKey(1)\n",
    "                if k == 27:\n",
    "                        self.cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Detector()\n",
    "\n",
    "for el in d.run_detection():\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f3cd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d98d3224617ef5756c5470cd79027a3f1600bbc153520c50096a0ac221592db"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('yolo_train')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
